{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef958316-3897-489d-b879-fa9d15ff89d0",
   "metadata": {},
   "source": [
    "# Resource\n",
    "[deepsphere (paper)](https://arxiv.org/abs/1810.12186)\n",
    "> [deepsphere-pytorch (github)](https://github.com/deepsphere/deepsphere-pytorch)\n",
    "\n",
    "[Cosmological Parameter Estimation and Inference using Deep Summaries (paper)](https://arxiv.org/abs/2107.09002)\n",
    "> [cosmo_estimators (github)](https://github.com/jafluri/cosmo_estimators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66260bb-f366-4916-a6be-fff929c9c634",
   "metadata": {},
   "source": [
    "# Official example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c83f2b8-7349-45ae-83ff-42adbe052dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from ignite.contrib.handlers.param_scheduler import create_lr_scheduler_with_warmup\n",
    "from ignite.contrib.handlers.tensorboard_logger import GradsHistHandler, OptimizerParamsHandler, OutputHandler, TensorboardLogger, WeightsHistHandler\n",
    "from ignite.engine import Engine, Events, create_supervised_evaluator\n",
    "from ignite.handlers import EarlyStopping, TerminateOnNan\n",
    "from ignite.metrics import EpochMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from deepsphere.data.transforms.transforms import Normalize, Permute, ToTensor\n",
    "from deepsphere.utils.initialization import init_dataset_temp, init_device, init_unet_temp\n",
    "from deepsphere.utils.parser import create_parser, parse_config\n",
    "from deepsphere.utils.stats_extractor import stats_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f696f5db-0f30-4c2f-95bc-fb7f96ac958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1 GPU(s) on this machine\n",
      "We are using GPU\n",
      "GPU is Tesla V100S-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "'''check GPU'''\n",
    "# let's see how many GPU we have?\n",
    "ngpu = torch.cuda.device_count()\n",
    "print(f\"We have {ngpu} GPU(s) on this machine\")\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"We are using GPU\")\n",
    "    print(f\"GPU is {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(f\"We are using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fcd6af6-2f87-4a9a-90d1-c46c8c74f113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1225b8dd-701c-4b09-9083-8d87ec2253f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_compute_fn(y_pred, y_true):\n",
    "    \"\"\"Attached function to the custom ignite metric AveragePrecisionMultiLabel\n",
    "\n",
    "    Args:\n",
    "        y_pred (:obj:`torch.Tensor`): model predictions\n",
    "        y_true (:obj:`torch.Tensor`): ground truths\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: Indicates that sklearn should be installed by the user.\n",
    "\n",
    "    Returns:\n",
    "        :obj:`numpy.array`: average precision vector.\n",
    "                            Of the same length as the number of labels present in the data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from sklearn.metrics import average_precision_score\n",
    "    except ImportError:\n",
    "        raise RuntimeError(\"This metric requires sklearn to be installed.\")\n",
    "\n",
    "    ap = average_precision_score(y_true.numpy(), y_pred.numpy(), None)\n",
    "    return ap\n",
    "\n",
    "\n",
    "# Pylint and Ignite incompatibilities:\n",
    "# pylint: disable=W0612\n",
    "# pylint: disable=W0613\n",
    "\n",
    "\n",
    "def validate_output_transform(x, y, y_pred):\n",
    "    \"\"\"A transform to format the output of the supervised evaluator before calculating the metric\n",
    "\n",
    "    Args:\n",
    "        x (:obj:`torch.Tensor`): the input to the model\n",
    "        y (:obj:`torch.Tensor`): the output of the model\n",
    "        y_pred (:obj:`torch.Tensor`): the ground truth labels\n",
    "\n",
    "    Returns:\n",
    "        (:obj:`torch.Tensor`, :obj:`torch.Tensor`): model predictions and ground truths reformatted\n",
    "    \"\"\"\n",
    "    output = y_pred\n",
    "    labels = y\n",
    "    B, V, C = output.shape\n",
    "    B_labels, V_labels, C_labels = labels.shape\n",
    "    output = output.view(B * V, C)\n",
    "    labels = labels.view(B_labels * V_labels, C_labels)\n",
    "    return output, labels\n",
    "\n",
    "\n",
    "def add_tensorboard(engine_train, optimizer, model, log_dir):\n",
    "    \"\"\"Creates an ignite logger object and adds training elements such as weight and gradient histograms\n",
    "\n",
    "    Args:\n",
    "        engine_train (:obj:`ignite.engine`): the train engine to attach to the logger\n",
    "        optimizer (:obj:`torch.optim`): the model's optimizer\n",
    "        model (:obj:`torch.nn.Module`): the model being trained\n",
    "        log_dir (string): path to where tensorboard data should be saved\n",
    "    \"\"\"\n",
    "    # Create a logger\n",
    "    tb_logger = TensorboardLogger(log_dir=log_dir)\n",
    "\n",
    "    # Attach the logger to the trainer to log training loss at each iteration\n",
    "    tb_logger.attach(\n",
    "        engine_train, log_handler=OutputHandler(tag=\"training\", output_transform=lambda loss: {\"loss\": loss}), event_name=Events.ITERATION_COMPLETED\n",
    "    )\n",
    "\n",
    "    # Attach the logger to the trainer to log optimizer's parameters, e.g. learning rate at each iteration\n",
    "    tb_logger.attach(engine_train, log_handler=OptimizerParamsHandler(optimizer), event_name=Events.EPOCH_COMPLETED)\n",
    "\n",
    "    # Attach the logger to the trainer to log model's weights as a histogram after each epoch\n",
    "    tb_logger.attach(engine_train, log_handler=WeightsHistHandler(model), event_name=Events.EPOCH_COMPLETED)\n",
    "\n",
    "    # Attach the logger to the trainer to log model's gradients as a histogram after each epoch\n",
    "    tb_logger.attach(engine_train, log_handler=GradsHistHandler(model), event_name=Events.EPOCH_COMPLETED)\n",
    "\n",
    "    tb_logger.close()\n",
    "\n",
    "\n",
    "def get_dataloaders(parser_args):\n",
    "    \"\"\"Creates the datasets and the corresponding dataloaders\n",
    "\n",
    "    Args:\n",
    "        parser_args (dict): parsed arguments\n",
    "\n",
    "    Returns:\n",
    "        (:obj:`torch.utils.data.dataloader`, :obj:`torch.utils.data.dataloader`): train, validation dataloaders\n",
    "    \"\"\"\n",
    "\n",
    "    partition = parser_args.partition\n",
    "    seed = parser_args.seed\n",
    "    means_path = parser_args.means_path\n",
    "    stds_path = parser_args.stds_path\n",
    "\n",
    "    data = init_dataset_temp(parser=parser_args, indices=None, transform_image=None, transform_labels=None)\n",
    "\n",
    "    train_indices, temp = train_test_split(data.indices, train_size=partition[0], random_state=seed)\n",
    "    val_indices, _ = train_test_split(temp, test_size=partition[2] / (partition[1] + partition[2]), random_state=seed)\n",
    "\n",
    "    if (means_path is None) or (stds_path is None):\n",
    "        transform_image_stats = transforms.Compose([ToTensor()])\n",
    "        train_set_stats = init_dataset_temp(parser=parser_args, indices=train_indices, transform_image=transform_image_stats, transform_labels=None)\n",
    "        means, stds = stats_extractor(train_set_stats)\n",
    "        np.save(\"./means.npy\", means)\n",
    "        np.save(\"./stds.npy\", stds)\n",
    "    else:\n",
    "        try:\n",
    "            means = np.load(means_path)\n",
    "            stds = np.load(stds_path)\n",
    "        except ValueError:\n",
    "            print(\"No means or stds were provided. Or path names incorrect.\")\n",
    "\n",
    "    transform_image = transforms.Compose([ToTensor(), Permute(), Normalize(mean=means, std=stds)])\n",
    "    transform_labels = transforms.Compose([ToTensor(), Permute()])\n",
    "    train_set = init_dataset_temp(parser=parser_args, indices=train_indices, transform_image=transform_image, transform_labels=transform_labels)\n",
    "    validation_set = init_dataset_temp(parser=parser_args, indices=val_indices, transform_image=transform_image, transform_labels=transform_labels)\n",
    "\n",
    "    dataloader_train = DataLoader(train_set, batch_size=parser_args.batch_size, shuffle=True, num_workers=12)\n",
    "    dataloader_validation = DataLoader(validation_set, batch_size=parser_args.batch_size, shuffle=False, num_workers=12)\n",
    "    return dataloader_train, dataloader_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe93e7df-19f9-4f3c-8a0a-bf82350be0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(parser_args):\n",
    "    \"\"\"Main function to create trainer engine, add handlers to train and validation engines.\n",
    "    Then runs train engine to perform training and validation.\n",
    "\n",
    "    Args:\n",
    "        parser_args (dict): parsed arguments\n",
    "    \"\"\"\n",
    "    dataloader_train, dataloader_validation = get_dataloaders(parser_args)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    unet = init_unet_temp(parser_args)\n",
    "    unet, device = init_device(parser_args.device, unet)\n",
    "\n",
    "    lr = parser_args.learning_rate\n",
    "    optimizer = optim.Adam(unet.parameters(), lr=lr)\n",
    "\n",
    "    def trainer(engine, batch):\n",
    "        \"\"\"Train Function to define train engine.\n",
    "        Called for every batch of the train engine, for each epoch.\n",
    "\n",
    "        Args:\n",
    "            engine (ignite.engine): train engine\n",
    "            batch (:obj:`torch.utils.data.dataloader`): batch from train dataloader\n",
    "\n",
    "        Returns:\n",
    "            :obj:`torch.tensor` : train loss for that batch and epoch\n",
    "        \"\"\"\n",
    "        unet.train()\n",
    "        data, labels = batch\n",
    "        labels = labels.to(device)\n",
    "        data = data.to(device)\n",
    "        # for sample in data:\n",
    "        #    sample = sample.to(device)\n",
    "        output = unet(data)\n",
    "\n",
    "        B, V, C = output.shape\n",
    "        B_labels, V_labels, C_labels = labels.shape\n",
    "        output = output.view(B * V, C)\n",
    "        labels = labels.view(B_labels * V_labels, C_labels).max(1)[1]\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    writer = SummaryWriter(parser_args.tensorboard_path)\n",
    "\n",
    "    engine_train = Engine(trainer)\n",
    "\n",
    "    engine_validate = create_supervised_evaluator(\n",
    "        model=unet, metrics={\"AP\": EpochMetric(average_precision_compute_fn)}, device=device, output_transform=validate_output_transform\n",
    "    )\n",
    "\n",
    "    engine_train.add_event_handler(Events.EPOCH_STARTED, lambda x: print(\"Starting Epoch: {}\".format(x.state.epoch)))\n",
    "    engine_train.add_event_handler(Events.ITERATION_COMPLETED, TerminateOnNan())\n",
    "\n",
    "    @engine_train.on(Events.EPOCH_COMPLETED)\n",
    "    def epoch_validation(engine):\n",
    "        \"\"\"Handler to run the validation engine at the end of the train engine's epoch.\n",
    "\n",
    "        Args:\n",
    "            engine (ignite.engine): train engine\n",
    "        \"\"\"\n",
    "        print(\"beginning validation epoch\")\n",
    "        engine_validate.run(dataloader_validation)\n",
    "\n",
    "    reduce_lr_plateau = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=parser_args.reducelronplateau_mode,\n",
    "        factor=parser_args.reducelronplateau_factor,\n",
    "        patience=parser_args.reducelronplateau_patience,\n",
    "    )\n",
    "\n",
    "    @engine_validate.on(Events.EPOCH_COMPLETED)\n",
    "    def update_reduce_on_plateau(engine):\n",
    "        \"\"\"Handler to reduce the learning rate on plateau at the end of the validation engine's epoch\n",
    "\n",
    "        Args:\n",
    "            engine (ignite.engine): validation engine\n",
    "        \"\"\"\n",
    "        ap = engine.state.metrics[\"AP\"]\n",
    "        mean_average_precision = np.mean(ap[1:])\n",
    "        reduce_lr_plateau.step(mean_average_precision)\n",
    "\n",
    "    @engine_validate.on(Events.EPOCH_COMPLETED)\n",
    "    def save_epoch_results(engine):\n",
    "        \"\"\"Handler to save the metrics at the end of the validation engine's epoch\n",
    "\n",
    "        Args:\n",
    "            engine (ignite.engine): validation engine\n",
    "        \"\"\"\n",
    "        ap = engine.state.metrics[\"AP\"]\n",
    "        mean_average_precision = np.mean(ap[1:])\n",
    "        print(\"Average precisions:\", ap)\n",
    "        print(\"mAP:\", mean_average_precision)\n",
    "        writer.add_scalars(\n",
    "            \"metrics\",\n",
    "            {\"mean average precision (AR+TC)\": mean_average_precision, \"AR average precision\": ap[2], \"TC average precision\": ap[1]},\n",
    "            engine_train.state.epoch,\n",
    "        )\n",
    "        writer.close()\n",
    "\n",
    "    step_scheduler = StepLR(optimizer, step_size=parser_args.steplr_step_size, gamma=parser_args.steplr_gamma)\n",
    "    scheduler = create_lr_scheduler_with_warmup(\n",
    "        step_scheduler,\n",
    "        warmup_start_value=parser_args.warmuplr_warmup_start_value,\n",
    "        warmup_end_value=parser_args.warmuplr_warmup_end_value,\n",
    "        warmup_duration=parser_args.warmuplr_warmup_duration,\n",
    "    )\n",
    "    engine_validate.add_event_handler(Events.EPOCH_COMPLETED, scheduler)\n",
    "\n",
    "    earlystopper = EarlyStopping(\n",
    "        patience=parser_args.earlystopping_patience, score_function=lambda x: -x.state.metrics[\"AP\"][1], trainer=engine_train\n",
    "    )\n",
    "    engine_validate.add_event_handler(Events.EPOCH_COMPLETED, earlystopper)\n",
    "\n",
    "    add_tensorboard(engine_train, optimizer, unet, log_dir=parser_args.tensorboard_path)\n",
    "\n",
    "    engine_train.run(dataloader_train, max_epochs=parser_args.n_epochs)\n",
    "\n",
    "    torch.save(unet.state_dict(), parser_args.model_save_path + \"unet_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d2daff9-eac4-4581-9844-80dd6c3a440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "def get_yaml_data(yaml_file):\n",
    "    file = open(yaml_file, 'r', encoding=\"utf-8\")\n",
    "    file_data = file.read()\n",
    "    file.close()\n",
    "    data = yaml.safe_load(file_data)\n",
    "    # print(data)\n",
    "    return data\n",
    "\n",
    "path_config = os.path.abspath(\".\") + '/config.yml'\n",
    "cfg = get_yaml_data(path_config)\n",
    "\n",
    "cfg_flat = dict()\n",
    "for key in cfg.keys():\n",
    "    val = cfg[key]\n",
    "    cfg_flat = {**val, **cfg_flat}\n",
    "\n",
    "cfg_flat['device'] = ''\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "cfg_attr = AttrDict(cfg_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45aeffe9-1a78-462f-8905-539baea6ea00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfg_flat['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a900db63-ddbf-44c1-b724-9160ef146832",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 17179869181.78 GiB (GPU 0; 31.75 GiB total capacity; 27.61 GiB already allocated; 3.14 GiB free; 19.82 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_255210/2252627224.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_255210/1339678332.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(parser_args)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_unet_temp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/anaconda3/envs/deepsphere/lib/python3.7/site-packages/deepsphere/utils/initialization.py\u001b[0m in \u001b[0;36minit_device\u001b[0;34m(device, unet)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/anaconda3/envs/deepsphere/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/anaconda3/envs/deepsphere/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/anaconda3/envs/deepsphere/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/anaconda3/envs/deepsphere/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     self.batch_first, bool(self.bidirectional))\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 17179869181.78 GiB (GPU 0; 31.75 GiB total capacity; 27.61 GiB already allocated; 3.14 GiB free; 19.82 MiB cached)"
     ]
    }
   ],
   "source": [
    "main(cfg_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fae571-47e7-4885-ab91-0b28e57bacdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85b5aa9c-a8dd-4af4-9693-c166bf6af653",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a05d1aad-3863-4878-b4ac-5241fca1c7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "'''define model'''\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class Polynomial3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate four parameters and assign them as\n",
    "        member parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()))\n",
    "        self.b = torch.nn.Parameter(torch.randn(()))\n",
    "        self.c = torch.nn.Parameter(torch.randn(()))\n",
    "        self.d = torch.nn.Parameter(torch.randn(()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
    "\n",
    "    def string(self):\n",
    "        \"\"\"\n",
    "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
    "        \"\"\"\n",
    "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3'\n",
    "    \n",
    "'''create model object'''\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = Polynomial3().to(device)\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000,device=device)\n",
    "y = torch.sin(x) #+ torch.pow(x,1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0795c318-54ef-4336-8dc7-79ad268e66f0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 8.817166328430176\n",
      "1999 8.817166328430176\n",
      "2999 8.817166328430176\n",
      "3999 8.817166328430176\n",
      "4999 8.817166328430176\n",
      "5999 8.817166328430176\n",
      "6999 8.817166328430176\n",
      "7999 8.817166328430176\n",
      "8999 8.817166328430176\n",
      "9999 8.817166328430176\n",
      "Result: y = -4.021410315857565e-09 + 0.8567265868186951 x + 1.1001342947736248e-08 x^2 + -0.09332836419343948 x^3\n"
     ]
    }
   ],
   "source": [
    "'''Train!'''\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "for t in range(10000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 1000 == 999:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Result: {model.string()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97817b4a-ca0b-4e2d-85ad-f85e62459162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1319.5826416015625\n",
      "199 661.7208251953125\n",
      "299 514.9322509765625\n",
      "399 470.4815673828125\n",
      "499 447.0289306640625\n",
      "599 428.34918212890625\n",
      "699 411.1867980957031\n",
      "799 394.87054443359375\n",
      "899 379.24456787109375\n",
      "999 364.2568359375\n",
      "1099 349.87677001953125\n",
      "1199 336.0787048339844\n",
      "1299 322.8390808105469\n",
      "1399 310.13507080078125\n",
      "1499 297.9451599121094\n",
      "1599 286.24847412109375\n",
      "1699 275.0248718261719\n",
      "1799 264.25543212890625\n",
      "1899 253.92169189453125\n",
      "1999 244.00611877441406\n",
      "Result: y = 0.03316299617290497 + 0.38542047142982483 x + -0.005721138324588537 x^2 + -0.02628917433321476 x^3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "947b59af-6589-4234-b8ba-250601289fef",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e058f7-c678-441a-973a-f2ad09c4d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b98c6-8d6a-4ca7-bbd7-4f5893d5d50b",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc49f6-4c00-4348-92ea-72b2799c9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from ignite.contrib.handlers.param_scheduler import create_lr_scheduler_with_warmup\n",
    "from ignite.contrib.handlers.tensorboard_logger import GradsHistHandler, OptimizerParamsHandler, OutputHandler, TensorboardLogger, WeightsHistHandler\n",
    "from ignite.engine import Engine, Events, create_supervised_evaluator\n",
    "from ignite.handlers import EarlyStopping, TerminateOnNan\n",
    "from ignite.metrics import EpochMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from deepsphere.data.datasets.dataset import ARTCDataset\n",
    "from deepsphere.data.transforms.transforms import Normalize, Permute, ToTensor\n",
    "from deepsphere.models.spherical_unet.unet_model import SphericalUNet\n",
    "from deepsphere.utils.initialization import init_device\n",
    "from deepsphere.utils.parser import create_parser, parse_config\n",
    "from deepsphere.utils.stats_extractor import stats_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d85cb6-f43f-465d-9ed3-b735a6470945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from deepsphere.utils.initialization import init_dataset_temp, init_device, init_unet_temp\n",
    "from deepsphere.utils.initialization import init_device\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "HOME = os.path.expandvars('$HOME')\n",
    "# dataset_dir=HOME+'/code/shear2convergence/recon_kappa/'\n",
    "dataset_dir = '/home/zysun/recon_kappa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092f6120-2495-476c-b7fe-313487f34da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save output to log file\n",
    "in case the Internet shut down or kernel crash\n",
    "'''\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "so = open(\"jupyterlab.log\", 'w', 10)\n",
    "sys.stdout.echo = so\n",
    "sys.stderr.echo = so\n",
    "\n",
    "get_ipython().log.handlers[0].stream = so\n",
    "get_ipython().log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0df92-5c7e-439a-8a7b-9270fbe8d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    ! sleep 1\n",
    "    print(i)\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7780f7b-5a26-4527-9911-fcd8e82029b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd3772-59f7-499b-ac6a-8d1ed699d285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsphere",
   "language": "python",
   "name": "deepsphere"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
